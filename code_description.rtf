{\rtf1\ansi\ansicpg1252\cocoartf2512
\cocoatextscaling0\cocoaplatform0{\fonttbl\f0\fnil\fcharset0 .SFNSMono-Regular;\f1\fnil\fcharset0 Menlo-Regular;}
{\colortbl;\red255\green255\blue255;\red0\green0\blue0;}
{\*\expandedcolortbl;;\csgray\c0;}
\margl1440\margr1440\vieww16960\viewh14560\viewkind0
\pard\tx560\tx1120\tx1680\tx2240\tx2800\tx3360\tx3920\tx4480\tx5040\tx5600\tx6160\tx6720\pardirnatural\partightenfactor0

\f0\fs38 \cf2 Code description\
\
This document describes the code for running the experiments in the context of the work \'93Towards Website Domain Name Classification Using Graph-Based Semi-supervised Learning.\'94\
The code runs with Python3.7 and requires the following libraries:\
- Scikit-Learn\
- scipy\
- numpy\
- nltk\
- keras\
- torch\
\
main.py\
The main takes in input the users\'92 activity dataset and the file with vectors of domains, the latter being used in SVM and the semi-supervised approach. \
The main.py script launches the execution of all the considered algorithms. \
It splits data into test and training data. Then for each method, it performs 10-fold cross-validation on training data. Based on the range of the defined parameter for each method, it tunes the parameters and finds the best result and best parameters. This operation is performed for each method through the 10-fold cross-validation. \
Finally, the code performs the best overall methodology on test data.\
 \
The experiments are executed calling separated methods, listed in the following:\
\
TFIDF.py\
This method assigns each website category based on domain names using TFIDF (Term Frequency\'96Inverse Document Frequency). TFIDF reflects how important an n-gram g is for a category c 
\f1 \uc0\u8712 
\f0  C to the set of all categories in the training model. For creating the training model of n_grams, it calls training_model.py\
\
NFA.py\
This method includes a methodology classify the domain leveraging Number of False Alarms (NFA), which expresses a similarity measure between a domain name and a category. For creating the training model of n_grams it calls training_model.py\
\
SVM.py\
This method considers as input a series of sessions, i.e., sequences of domains visited by a user in one hour.\
It leverages Word2Vec model (fastText <=> https://github.com/facebookresearch/fastText ) to represent the session as a vector in a vector space (the vectors are stored and directly usable using the file vectordomain.txt)\
It represents each domain name with a very low-dimensional vector with semantic meaning. Ultimately, SVM assigns categories to domains. \
\
\
Semi_Supervised_Graph.py\
This method builds the graphs using input data domain names, sessions, or a combination of both by calling the Create_Graph method. Then for classifying the domains based on graph semi-supervised learning, it calls semi_supervised.py, which contains the LGC method to perform the classification.\
\
\
LSTM.py\
This method executes the LSTM (https://www.tensorflow.org/guide/keras/rnn) algorithm, taking in input domain names as a series of characters.}